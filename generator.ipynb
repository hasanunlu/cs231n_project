{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Part of the training and accuracy check were taken from assigment-2\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "def check_accuracy_part(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc\n",
    "def train_part(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on MNIST using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    best_acc = -1\n",
    "    best_model = None\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(data_train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                acc = check_accuracy_part(data_test_loader, model)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model = model\n",
    "                print()\n",
    "    print('Best accuracy found', best_acc)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "using device: cuda\n",
      "Iteration 0, loss = 2.3002\n",
      "Checking accuracy on test set\n",
      "Got 1191 / 10000 correct (11.91)\n",
      "\n",
      "Iteration 50, loss = 1.8161\n",
      "Checking accuracy on test set\n",
      "Got 3685 / 10000 correct (36.85)\n",
      "\n",
      "Iteration 100, loss = 1.4629\n",
      "Checking accuracy on test set\n",
      "Got 4464 / 10000 correct (44.64)\n",
      "\n",
      "Iteration 150, loss = 1.5112\n",
      "Checking accuracy on test set\n",
      "Got 4611 / 10000 correct (46.11)\n",
      "\n",
      "Iteration 200, loss = 1.4151\n",
      "Checking accuracy on test set\n",
      "Got 4901 / 10000 correct (49.01)\n",
      "\n",
      "Iteration 250, loss = 1.5460\n",
      "Checking accuracy on test set\n",
      "Got 5101 / 10000 correct (51.01)\n",
      "\n",
      "Iteration 300, loss = 1.3393\n",
      "Checking accuracy on test set\n",
      "Got 5106 / 10000 correct (51.06)\n",
      "\n",
      "Iteration 350, loss = 1.3083\n",
      "Checking accuracy on test set\n",
      "Got 5381 / 10000 correct (53.81)\n",
      "\n",
      "Iteration 0, loss = 1.2506\n",
      "Checking accuracy on test set\n",
      "Got 5258 / 10000 correct (52.58)\n",
      "\n",
      "Iteration 50, loss = 1.3756\n",
      "Checking accuracy on test set\n",
      "Got 5560 / 10000 correct (55.60)\n",
      "\n",
      "Iteration 100, loss = 1.2145\n",
      "Checking accuracy on test set\n",
      "Got 5698 / 10000 correct (56.98)\n",
      "\n",
      "Iteration 150, loss = 1.1099\n",
      "Checking accuracy on test set\n",
      "Got 5795 / 10000 correct (57.95)\n",
      "\n",
      "Iteration 200, loss = 1.1387\n",
      "Checking accuracy on test set\n",
      "Got 5974 / 10000 correct (59.74)\n",
      "\n",
      "Iteration 250, loss = 1.2567\n",
      "Checking accuracy on test set\n",
      "Got 6022 / 10000 correct (60.22)\n",
      "\n",
      "Iteration 300, loss = 1.1549\n",
      "Checking accuracy on test set\n",
      "Got 5894 / 10000 correct (58.94)\n",
      "\n",
      "Iteration 350, loss = 1.0866\n",
      "Checking accuracy on test set\n",
      "Got 6049 / 10000 correct (60.49)\n",
      "\n",
      "Iteration 0, loss = 1.2307\n",
      "Checking accuracy on test set\n",
      "Got 5832 / 10000 correct (58.32)\n",
      "\n",
      "Iteration 50, loss = 1.0464\n",
      "Checking accuracy on test set\n",
      "Got 6142 / 10000 correct (61.42)\n",
      "\n",
      "Iteration 100, loss = 0.9660\n",
      "Checking accuracy on test set\n",
      "Got 6338 / 10000 correct (63.38)\n",
      "\n",
      "Iteration 150, loss = 0.9868\n",
      "Checking accuracy on test set\n",
      "Got 6274 / 10000 correct (62.74)\n",
      "\n",
      "Iteration 200, loss = 0.8344\n",
      "Checking accuracy on test set\n",
      "Got 6325 / 10000 correct (63.25)\n",
      "\n",
      "Iteration 250, loss = 1.0152\n",
      "Checking accuracy on test set\n",
      "Got 6386 / 10000 correct (63.86)\n",
      "\n",
      "Iteration 300, loss = 1.1090\n",
      "Checking accuracy on test set\n",
      "Got 6233 / 10000 correct (62.33)\n",
      "\n",
      "Iteration 350, loss = 0.9549\n",
      "Checking accuracy on test set\n",
      "Got 6475 / 10000 correct (64.75)\n",
      "\n",
      "Iteration 0, loss = 0.9586\n",
      "Checking accuracy on test set\n",
      "Got 6392 / 10000 correct (63.92)\n",
      "\n",
      "Iteration 50, loss = 0.9205\n",
      "Checking accuracy on test set\n",
      "Got 6517 / 10000 correct (65.17)\n",
      "\n",
      "Iteration 100, loss = 0.8950\n",
      "Checking accuracy on test set\n",
      "Got 6560 / 10000 correct (65.60)\n",
      "\n",
      "Iteration 150, loss = 0.9237\n",
      "Checking accuracy on test set\n",
      "Got 6511 / 10000 correct (65.11)\n",
      "\n",
      "Iteration 200, loss = 1.0214\n",
      "Checking accuracy on test set\n",
      "Got 6439 / 10000 correct (64.39)\n",
      "\n",
      "Iteration 250, loss = 0.9729\n",
      "Checking accuracy on test set\n",
      "Got 6484 / 10000 correct (64.84)\n",
      "\n",
      "Iteration 300, loss = 0.8551\n",
      "Checking accuracy on test set\n",
      "Got 6635 / 10000 correct (66.35)\n",
      "\n",
      "Iteration 350, loss = 0.7391\n",
      "Checking accuracy on test set\n",
      "Got 6754 / 10000 correct (67.54)\n",
      "\n",
      "Iteration 0, loss = 0.8139\n",
      "Checking accuracy on test set\n",
      "Got 6736 / 10000 correct (67.36)\n",
      "\n",
      "Iteration 50, loss = 0.9174\n",
      "Checking accuracy on test set\n",
      "Got 6758 / 10000 correct (67.58)\n",
      "\n",
      "Iteration 100, loss = 0.7656\n",
      "Checking accuracy on test set\n",
      "Got 6661 / 10000 correct (66.61)\n",
      "\n",
      "Iteration 150, loss = 0.9521\n",
      "Checking accuracy on test set\n",
      "Got 6704 / 10000 correct (67.04)\n",
      "\n",
      "Iteration 200, loss = 0.6967\n",
      "Checking accuracy on test set\n",
      "Got 6846 / 10000 correct (68.46)\n",
      "\n",
      "Iteration 250, loss = 0.8012\n",
      "Checking accuracy on test set\n",
      "Got 6795 / 10000 correct (67.95)\n",
      "\n",
      "Iteration 300, loss = 0.9864\n",
      "Checking accuracy on test set\n",
      "Got 6698 / 10000 correct (66.98)\n",
      "\n",
      "Iteration 350, loss = 0.8746\n",
      "Checking accuracy on test set\n",
      "Got 6916 / 10000 correct (69.16)\n",
      "\n",
      "Iteration 0, loss = 0.9427\n",
      "Checking accuracy on test set\n",
      "Got 6706 / 10000 correct (67.06)\n",
      "\n",
      "Iteration 50, loss = 0.6625\n",
      "Checking accuracy on test set\n",
      "Got 6639 / 10000 correct (66.39)\n",
      "\n",
      "Iteration 100, loss = 0.8337\n",
      "Checking accuracy on test set\n",
      "Got 6774 / 10000 correct (67.74)\n",
      "\n",
      "Iteration 150, loss = 0.7361\n",
      "Checking accuracy on test set\n",
      "Got 6804 / 10000 correct (68.04)\n",
      "\n",
      "Iteration 200, loss = 0.6856\n",
      "Checking accuracy on test set\n",
      "Got 6861 / 10000 correct (68.61)\n",
      "\n",
      "Iteration 250, loss = 0.6787\n",
      "Checking accuracy on test set\n",
      "Got 6843 / 10000 correct (68.43)\n",
      "\n",
      "Iteration 300, loss = 0.9076\n",
      "Checking accuracy on test set\n",
      "Got 6845 / 10000 correct (68.45)\n",
      "\n",
      "Iteration 350, loss = 0.8596\n",
      "Checking accuracy on test set\n",
      "Got 6872 / 10000 correct (68.72)\n",
      "\n",
      "Iteration 0, loss = 0.6403\n",
      "Checking accuracy on test set\n",
      "Got 6844 / 10000 correct (68.44)\n",
      "\n",
      "Iteration 50, loss = 0.7887\n",
      "Checking accuracy on test set\n",
      "Got 6986 / 10000 correct (69.86)\n",
      "\n",
      "Iteration 100, loss = 0.6400\n",
      "Checking accuracy on test set\n",
      "Got 6917 / 10000 correct (69.17)\n",
      "\n",
      "Iteration 150, loss = 0.5822\n",
      "Checking accuracy on test set\n",
      "Got 7033 / 10000 correct (70.33)\n",
      "\n",
      "Iteration 200, loss = 0.7864\n",
      "Checking accuracy on test set\n",
      "Got 6806 / 10000 correct (68.06)\n",
      "\n",
      "Iteration 250, loss = 0.8393\n",
      "Checking accuracy on test set\n",
      "Got 7006 / 10000 correct (70.06)\n",
      "\n",
      "Iteration 300, loss = 0.7503\n",
      "Checking accuracy on test set\n",
      "Got 6890 / 10000 correct (68.90)\n",
      "\n",
      "Iteration 350, loss = 0.8386\n",
      "Checking accuracy on test set\n",
      "Got 7051 / 10000 correct (70.51)\n",
      "\n",
      "Iteration 0, loss = 0.5294\n",
      "Checking accuracy on test set\n",
      "Got 7011 / 10000 correct (70.11)\n",
      "\n",
      "Iteration 50, loss = 0.7726\n",
      "Checking accuracy on test set\n",
      "Got 6774 / 10000 correct (67.74)\n",
      "\n",
      "Iteration 100, loss = 0.7340\n",
      "Checking accuracy on test set\n",
      "Got 6959 / 10000 correct (69.59)\n",
      "\n",
      "Iteration 150, loss = 0.8194\n",
      "Checking accuracy on test set\n",
      "Got 6992 / 10000 correct (69.92)\n",
      "\n",
      "Iteration 200, loss = 0.7179\n",
      "Checking accuracy on test set\n",
      "Got 6888 / 10000 correct (68.88)\n",
      "\n",
      "Iteration 250, loss = 0.7695\n",
      "Checking accuracy on test set\n",
      "Got 6982 / 10000 correct (69.82)\n",
      "\n",
      "Iteration 300, loss = 0.6244\n",
      "Checking accuracy on test set\n",
      "Got 6919 / 10000 correct (69.19)\n",
      "\n",
      "Iteration 350, loss = 0.9683\n",
      "Checking accuracy on test set\n",
      "Got 7145 / 10000 correct (71.45)\n",
      "\n",
      "Iteration 0, loss = 0.6400\n",
      "Checking accuracy on test set\n",
      "Got 7044 / 10000 correct (70.44)\n",
      "\n",
      "Iteration 50, loss = 0.7831\n",
      "Checking accuracy on test set\n",
      "Got 7046 / 10000 correct (70.46)\n",
      "\n",
      "Iteration 100, loss = 0.6686\n",
      "Checking accuracy on test set\n",
      "Got 7064 / 10000 correct (70.64)\n",
      "\n",
      "Iteration 150, loss = 0.5955\n",
      "Checking accuracy on test set\n",
      "Got 7074 / 10000 correct (70.74)\n",
      "\n",
      "Iteration 200, loss = 0.5080\n",
      "Checking accuracy on test set\n",
      "Got 7092 / 10000 correct (70.92)\n",
      "\n",
      "Iteration 250, loss = 0.8205\n",
      "Checking accuracy on test set\n",
      "Got 6888 / 10000 correct (68.88)\n",
      "\n",
      "Iteration 300, loss = 0.7152\n",
      "Checking accuracy on test set\n",
      "Got 6987 / 10000 correct (69.87)\n",
      "\n",
      "Iteration 350, loss = 0.6067\n",
      "Checking accuracy on test set\n",
      "Got 6839 / 10000 correct (68.39)\n",
      "\n",
      "Iteration 0, loss = 0.8325\n",
      "Checking accuracy on test set\n",
      "Got 7063 / 10000 correct (70.63)\n",
      "\n",
      "Iteration 50, loss = 0.5000\n",
      "Checking accuracy on test set\n",
      "Got 7011 / 10000 correct (70.11)\n",
      "\n",
      "Iteration 100, loss = 0.6554\n",
      "Checking accuracy on test set\n",
      "Got 7075 / 10000 correct (70.75)\n",
      "\n",
      "Iteration 150, loss = 0.5906\n",
      "Checking accuracy on test set\n",
      "Got 6910 / 10000 correct (69.10)\n",
      "\n",
      "Iteration 200, loss = 0.5698\n",
      "Checking accuracy on test set\n",
      "Got 6872 / 10000 correct (68.72)\n",
      "\n",
      "Iteration 250, loss = 0.6715\n",
      "Checking accuracy on test set\n",
      "Got 7123 / 10000 correct (71.23)\n",
      "\n",
      "Iteration 300, loss = 0.7645\n",
      "Checking accuracy on test set\n",
      "Got 7082 / 10000 correct (70.82)\n",
      "\n",
      "Iteration 350, loss = 0.6441\n",
      "Checking accuracy on test set\n",
      "Got 7091 / 10000 correct (70.91)\n",
      "\n",
      "Iteration 0, loss = 0.6506\n",
      "Checking accuracy on test set\n",
      "Got 6979 / 10000 correct (69.79)\n",
      "\n",
      "Iteration 50, loss = 0.6965\n",
      "Checking accuracy on test set\n",
      "Got 7065 / 10000 correct (70.65)\n",
      "\n",
      "Iteration 100, loss = 0.4307\n",
      "Checking accuracy on test set\n",
      "Got 7095 / 10000 correct (70.95)\n",
      "\n",
      "Iteration 150, loss = 0.6983\n",
      "Checking accuracy on test set\n",
      "Got 7097 / 10000 correct (70.97)\n",
      "\n",
      "Iteration 200, loss = 0.6914\n",
      "Checking accuracy on test set\n",
      "Got 7126 / 10000 correct (71.26)\n",
      "\n",
      "Iteration 250, loss = 0.6950\n",
      "Checking accuracy on test set\n",
      "Got 6990 / 10000 correct (69.90)\n",
      "\n",
      "Iteration 300, loss = 0.6658\n",
      "Checking accuracy on test set\n",
      "Got 7001 / 10000 correct (70.01)\n",
      "\n",
      "Iteration 350, loss = 0.6767\n",
      "Checking accuracy on test set\n",
      "Got 7022 / 10000 correct (70.22)\n",
      "\n",
      "Iteration 0, loss = 0.5175\n",
      "Checking accuracy on test set\n",
      "Got 7043 / 10000 correct (70.43)\n",
      "\n",
      "Iteration 50, loss = 0.7127\n",
      "Checking accuracy on test set\n",
      "Got 6990 / 10000 correct (69.90)\n",
      "\n",
      "Iteration 100, loss = 0.7949\n",
      "Checking accuracy on test set\n",
      "Got 7103 / 10000 correct (71.03)\n",
      "\n",
      "Iteration 150, loss = 0.6989\n",
      "Checking accuracy on test set\n",
      "Got 7075 / 10000 correct (70.75)\n",
      "\n",
      "Iteration 200, loss = 0.5740\n",
      "Checking accuracy on test set\n",
      "Got 7060 / 10000 correct (70.60)\n",
      "\n",
      "Iteration 250, loss = 0.4989\n",
      "Checking accuracy on test set\n",
      "Got 6991 / 10000 correct (69.91)\n",
      "\n",
      "Iteration 300, loss = 0.6829\n",
      "Checking accuracy on test set\n",
      "Got 7092 / 10000 correct (70.92)\n",
      "\n",
      "Iteration 350, loss = 0.7218\n",
      "Checking accuracy on test set\n",
      "Got 7071 / 10000 correct (70.71)\n",
      "\n",
      "Iteration 0, loss = 0.5659\n",
      "Checking accuracy on test set\n",
      "Got 7099 / 10000 correct (70.99)\n",
      "\n",
      "Iteration 50, loss = 0.5163\n",
      "Checking accuracy on test set\n",
      "Got 7122 / 10000 correct (71.22)\n",
      "\n",
      "Iteration 100, loss = 0.7737\n",
      "Checking accuracy on test set\n",
      "Got 7048 / 10000 correct (70.48)\n",
      "\n",
      "Iteration 150, loss = 0.7888\n",
      "Checking accuracy on test set\n",
      "Got 7126 / 10000 correct (71.26)\n",
      "\n",
      "Iteration 200, loss = 0.6685\n",
      "Checking accuracy on test set\n",
      "Got 7065 / 10000 correct (70.65)\n",
      "\n",
      "Iteration 250, loss = 0.6039\n",
      "Checking accuracy on test set\n",
      "Got 7045 / 10000 correct (70.45)\n",
      "\n",
      "Iteration 300, loss = 0.5973\n",
      "Checking accuracy on test set\n",
      "Got 7143 / 10000 correct (71.43)\n",
      "\n",
      "Iteration 350, loss = 0.7132\n",
      "Checking accuracy on test set\n",
      "Got 7023 / 10000 correct (70.23)\n",
      "\n",
      "Iteration 0, loss = 0.4393\n",
      "Checking accuracy on test set\n",
      "Got 7109 / 10000 correct (71.09)\n",
      "\n",
      "Iteration 50, loss = 0.5648\n",
      "Checking accuracy on test set\n",
      "Got 7134 / 10000 correct (71.34)\n",
      "\n",
      "Iteration 100, loss = 0.6021\n",
      "Checking accuracy on test set\n",
      "Got 7061 / 10000 correct (70.61)\n",
      "\n",
      "Iteration 150, loss = 0.4706\n",
      "Checking accuracy on test set\n",
      "Got 7096 / 10000 correct (70.96)\n",
      "\n",
      "Iteration 200, loss = 0.5752\n",
      "Checking accuracy on test set\n",
      "Got 7066 / 10000 correct (70.66)\n",
      "\n",
      "Iteration 250, loss = 0.6154\n",
      "Checking accuracy on test set\n",
      "Got 7164 / 10000 correct (71.64)\n",
      "\n",
      "Iteration 300, loss = 0.6057\n",
      "Checking accuracy on test set\n",
      "Got 6922 / 10000 correct (69.22)\n",
      "\n",
      "Iteration 350, loss = 0.7689\n",
      "Checking accuracy on test set\n",
      "Got 7074 / 10000 correct (70.74)\n",
      "\n",
      "Iteration 0, loss = 0.4739\n",
      "Checking accuracy on test set\n",
      "Got 7037 / 10000 correct (70.37)\n",
      "\n",
      "Iteration 50, loss = 0.5684\n",
      "Checking accuracy on test set\n",
      "Got 6976 / 10000 correct (69.76)\n",
      "\n",
      "Iteration 100, loss = 0.5647\n",
      "Checking accuracy on test set\n",
      "Got 7059 / 10000 correct (70.59)\n",
      "\n",
      "Iteration 150, loss = 0.4313\n",
      "Checking accuracy on test set\n",
      "Got 7070 / 10000 correct (70.70)\n",
      "\n",
      "Iteration 200, loss = 0.6256\n",
      "Checking accuracy on test set\n",
      "Got 7102 / 10000 correct (71.02)\n",
      "\n",
      "Iteration 250, loss = 0.8447\n",
      "Checking accuracy on test set\n",
      "Got 7097 / 10000 correct (70.97)\n",
      "\n",
      "Iteration 300, loss = 0.4919\n",
      "Checking accuracy on test set\n",
      "Got 7040 / 10000 correct (70.40)\n",
      "\n",
      "Iteration 350, loss = 0.7102\n",
      "Checking accuracy on test set\n",
      "Got 7097 / 10000 correct (70.97)\n",
      "\n",
      "Iteration 0, loss = 0.5164\n",
      "Checking accuracy on test set\n",
      "Got 7132 / 10000 correct (71.32)\n",
      "\n",
      "Iteration 50, loss = 0.5334\n",
      "Checking accuracy on test set\n",
      "Got 7100 / 10000 correct (71.00)\n",
      "\n",
      "Iteration 100, loss = 0.6734\n",
      "Checking accuracy on test set\n",
      "Got 6823 / 10000 correct (68.23)\n",
      "\n",
      "Iteration 150, loss = 0.6415\n",
      "Checking accuracy on test set\n",
      "Got 7072 / 10000 correct (70.72)\n",
      "\n",
      "Iteration 200, loss = 0.6037\n",
      "Checking accuracy on test set\n",
      "Got 7122 / 10000 correct (71.22)\n",
      "\n",
      "Iteration 250, loss = 0.5506\n",
      "Checking accuracy on test set\n",
      "Got 7135 / 10000 correct (71.35)\n",
      "\n",
      "Iteration 300, loss = 0.6104\n",
      "Checking accuracy on test set\n",
      "Got 7017 / 10000 correct (70.17)\n",
      "\n",
      "Iteration 350, loss = 0.6437\n",
      "Checking accuracy on test set\n",
      "Got 7109 / 10000 correct (71.09)\n",
      "\n",
      "Iteration 0, loss = 0.5206\n",
      "Checking accuracy on test set\n",
      "Got 7023 / 10000 correct (70.23)\n",
      "\n",
      "Iteration 50, loss = 0.5597\n",
      "Checking accuracy on test set\n",
      "Got 7076 / 10000 correct (70.76)\n",
      "\n",
      "Iteration 100, loss = 0.6159\n",
      "Checking accuracy on test set\n",
      "Got 7083 / 10000 correct (70.83)\n",
      "\n",
      "Iteration 150, loss = 0.5971\n",
      "Checking accuracy on test set\n",
      "Got 6961 / 10000 correct (69.61)\n",
      "\n",
      "Iteration 200, loss = 0.6245\n",
      "Checking accuracy on test set\n",
      "Got 7043 / 10000 correct (70.43)\n",
      "\n",
      "Iteration 250, loss = 0.9321\n",
      "Checking accuracy on test set\n",
      "Got 6969 / 10000 correct (69.69)\n",
      "\n",
      "Iteration 300, loss = 0.6294\n",
      "Checking accuracy on test set\n",
      "Got 7078 / 10000 correct (70.78)\n",
      "\n",
      "Iteration 350, loss = 0.5740\n",
      "Checking accuracy on test set\n",
      "Got 7089 / 10000 correct (70.89)\n",
      "\n",
      "Iteration 0, loss = 0.5152\n",
      "Checking accuracy on test set\n",
      "Got 7060 / 10000 correct (70.60)\n",
      "\n",
      "Iteration 50, loss = 0.5677\n",
      "Checking accuracy on test set\n",
      "Got 7022 / 10000 correct (70.22)\n",
      "\n",
      "Iteration 100, loss = 0.4082\n",
      "Checking accuracy on test set\n",
      "Got 7113 / 10000 correct (71.13)\n",
      "\n",
      "Iteration 150, loss = 0.7336\n",
      "Checking accuracy on test set\n",
      "Got 6998 / 10000 correct (69.98)\n",
      "\n",
      "Iteration 200, loss = 0.6087\n",
      "Checking accuracy on test set\n",
      "Got 7051 / 10000 correct (70.51)\n",
      "\n",
      "Iteration 250, loss = 0.5202\n",
      "Checking accuracy on test set\n",
      "Got 7085 / 10000 correct (70.85)\n",
      "\n",
      "Iteration 300, loss = 0.5411\n",
      "Checking accuracy on test set\n",
      "Got 7014 / 10000 correct (70.14)\n",
      "\n",
      "Iteration 350, loss = 0.4686\n",
      "Checking accuracy on test set\n",
      "Got 7125 / 10000 correct (71.25)\n",
      "\n",
      "Iteration 0, loss = 0.6001\n",
      "Checking accuracy on test set\n",
      "Got 7016 / 10000 correct (70.16)\n",
      "\n",
      "Iteration 50, loss = 0.7716\n",
      "Checking accuracy on test set\n",
      "Got 7071 / 10000 correct (70.71)\n",
      "\n",
      "Iteration 100, loss = 0.6397\n",
      "Checking accuracy on test set\n",
      "Got 6972 / 10000 correct (69.72)\n",
      "\n",
      "Iteration 150, loss = 0.4009\n",
      "Checking accuracy on test set\n",
      "Got 7053 / 10000 correct (70.53)\n",
      "\n",
      "Iteration 200, loss = 0.7345\n",
      "Checking accuracy on test set\n",
      "Got 7083 / 10000 correct (70.83)\n",
      "\n",
      "Iteration 250, loss = 0.5184\n",
      "Checking accuracy on test set\n",
      "Got 6908 / 10000 correct (69.08)\n",
      "\n",
      "Iteration 300, loss = 0.5184\n",
      "Checking accuracy on test set\n",
      "Got 7072 / 10000 correct (70.72)\n",
      "\n",
      "Iteration 350, loss = 0.6149\n",
      "Checking accuracy on test set\n",
      "Got 6898 / 10000 correct (68.98)\n",
      "\n",
      "Iteration 0, loss = 0.6377\n",
      "Checking accuracy on test set\n",
      "Got 7044 / 10000 correct (70.44)\n",
      "\n",
      "Iteration 50, loss = 0.6120\n",
      "Checking accuracy on test set\n",
      "Got 7054 / 10000 correct (70.54)\n",
      "\n",
      "Iteration 100, loss = 0.4294\n",
      "Checking accuracy on test set\n",
      "Got 7062 / 10000 correct (70.62)\n",
      "\n",
      "Iteration 150, loss = 0.5739\n",
      "Checking accuracy on test set\n",
      "Got 7130 / 10000 correct (71.30)\n",
      "\n",
      "Iteration 200, loss = 0.6845\n",
      "Checking accuracy on test set\n",
      "Got 7028 / 10000 correct (70.28)\n",
      "\n",
      "Iteration 250, loss = 0.6510\n",
      "Checking accuracy on test set\n",
      "Got 7016 / 10000 correct (70.16)\n",
      "\n",
      "Iteration 300, loss = 0.5965\n",
      "Checking accuracy on test set\n",
      "Got 7013 / 10000 correct (70.13)\n",
      "\n",
      "Iteration 350, loss = 0.6461\n",
      "Checking accuracy on test set\n",
      "Got 7009 / 10000 correct (70.09)\n",
      "\n",
      "Best accuracy found 0.7164\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (7): ReLU()\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Flatten()\n",
      "  (10): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = dset.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "data_train_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = dset.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "data_test_loader = torch.utils.data.DataLoader(testset, batch_size=512,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print_every = 50\n",
    "print('using device:', device)\n",
    "\n",
    "\n",
    "# Lenet-5 architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=2),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    nn.Linear(4*4*32, 10),\n",
    ")\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=2e-2, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "best_model = train_part(model, optimizer, 20)\n",
    "\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_0_weight_2d (32, 3, 5, 5)\n",
      "w_3_weight_2d (16, 32, 5, 5)\n",
      "w_6_weight_2d (32, 16, 5, 5)\n",
      "w_10_weight_2d (10, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "torch.Size([512, 10])\n",
      "tensor([ -2.4617, -10.9535,   4.2651,   1.8123,   0.4399,   2.2980,  -1.2447,\n",
      "         -3.6330,  -7.4688,  -9.5007], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) \n",
      " prediction: tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# weights header generator. This generates main.h\n",
    "\n",
    "weights_file = open('main.h', 'w')\n",
    "\n",
    "weights_file.write('typedef float data_t;\\n\\\n",
    "\\n\\\n",
    "typedef struct twoD\\n\\\n",
    "{\\n\\\n",
    "\tuint32_t r;\\n\\\n",
    "\tuint32_t c;\\n\\\n",
    "\tuint32_t in_channel;\\n\\\n",
    "\tuint32_t channel;\\n\\\n",
    "\tdata_t *data;\\n\\\n",
    "\tdata_t *bias;\\n\\\n",
    "} twoD_t;\\n\\n')\n",
    "\n",
    "prev_shapes = None\n",
    "prev_arr_name = None\n",
    "\n",
    "for name, param in best_model.state_dict().items():\n",
    "    arr = param.cpu().numpy();\n",
    "    shape_of_params = arr.shape\n",
    "    param_size =  len(arr.flatten())\n",
    "    #print(name, 'param size:', param_size)\n",
    "    underscore_arr_name = 'w_'+name.replace('.', '_')\n",
    "    array_name  = underscore_arr_name + '[' + str(param_size) + ']=' \n",
    "    weights_file.write('const data_t '+array_name+'{')\n",
    "    np.savetxt(weights_file, arr.flatten(), newline=',')\n",
    "    weights_file.write('};\\n\\n')\n",
    "    if len(shape_of_params) == 1:\n",
    "        if len(prev_shapes) > 2:\n",
    "            out_channel = prev_shapes[0]\n",
    "            in_channel = prev_shapes[1]\n",
    "        else:\n",
    "            out_channel = 1\n",
    "            in_channel = 1\n",
    "\n",
    "        weights_file.write('const twoD_t '+prev_arr_name+'_2d = {\\n\\\n",
    "                           .r = '+ str(prev_shapes[-1]) +',\\n\\\n",
    "                           .c = '+str(prev_shapes[-2])+',\\n\\\n",
    "                           .in_channel = '+str(in_channel)+',\\n\\\n",
    "                           .channel = '+str(out_channel)+',\\n\\\n",
    "                           .data = '+prev_arr_name+',\\n\\\n",
    "                           .bias = '+underscore_arr_name+'\\n\\\n",
    "                       };\\n\\n')\n",
    "        print(prev_arr_name+'_2d', prev_shapes)\n",
    "    prev_shapes = shape_of_params\n",
    "    prev_arr_name = underscore_arr_name\n",
    "\n",
    "    \n",
    "class lenet5_partial(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(lenet5_partial, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-6])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "lenet_debug = lenet5_partial(best_model)\n",
    "\n",
    "\n",
    "for i, (images, labels) in enumerate(data_test_loader):\n",
    "    if i == 5:\n",
    "        selected_in_batch = 100\n",
    "        img = images[selected_in_batch].numpy()\n",
    "        print(img.shape)\n",
    "        plt.imshow(img.transpose(1,2,0), vmin=0, vmax=1)\n",
    "        \n",
    "        weights_file.write('const data_t test['+str(img.size)+']={')\n",
    "        np.savetxt(weights_file, images[selected_in_batch].flatten(), newline=',')\n",
    "        weights_file.write('};\\n')\n",
    "\n",
    "        images = images.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        #output = lenet_debug(images)\n",
    "        output = best_model(images)\n",
    "        print(output.shape)\n",
    "        _, preds = output.max(axis=1)\n",
    "        #print(output[selected_in_batch, 0])\n",
    "        print(output[selected_in_batch], '\\n prediction:', preds[selected_in_batch])\n",
    "        break\n",
    "\n",
    "weights_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
